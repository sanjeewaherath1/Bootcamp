{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNksHa39hUylS4xJcLiarZZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4dabee00aa8040e6956f6b99335ba3b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8e18d328c594a25a039721e2458e0a0","IPY_MODEL_c8bd0d7d622b45e28f49ef59440ade2b","IPY_MODEL_e0f13939529f45d8a644df8ae2f2c97a"],"layout":"IPY_MODEL_367a3afaf05a49f5bfcdfe22ad35a2dc"}},"d8e18d328c594a25a039721e2458e0a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e10f81d2f4f477ab4b6621dadcf5358","placeholder":"​","style":"IPY_MODEL_9e3bd80a2d314c9ab8fa603edfc2c379","value":"tokenizer_config.json: 100%"}},"c8bd0d7d622b45e28f49ef59440ade2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26ce608df72547c48d6cae929067621d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59bdc4ac36db4f28928f3ddf80e7b170","value":48}},"e0f13939529f45d8a644df8ae2f2c97a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9700e34f794245629d6ffe941dc0647a","placeholder":"​","style":"IPY_MODEL_f7cda8c6a3f241ea866a520c3c952d7a","value":" 48.0/48.0 [00:00&lt;00:00, 1.69kB/s]"}},"367a3afaf05a49f5bfcdfe22ad35a2dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e10f81d2f4f477ab4b6621dadcf5358":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e3bd80a2d314c9ab8fa603edfc2c379":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26ce608df72547c48d6cae929067621d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59bdc4ac36db4f28928f3ddf80e7b170":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9700e34f794245629d6ffe941dc0647a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7cda8c6a3f241ea866a520c3c952d7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7b3bc0f86634640b762a3f63aee7984":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbcb723b101a4627a5a159e1dd7fdac8","IPY_MODEL_4351de0511504dbfa86b79083e9a3b90","IPY_MODEL_12c0a64499f24a91a7ba88767f0bb501"],"layout":"IPY_MODEL_87b5c1ea6b9b4ecfa9f19152402422e8"}},"fbcb723b101a4627a5a159e1dd7fdac8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fb6a06384f54c3c8cbaa86e5d3574ac","placeholder":"​","style":"IPY_MODEL_fc081ab84a8041efab0391c987dd5bb3","value":"config.json: 100%"}},"4351de0511504dbfa86b79083e9a3b90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab01437940aa4da5827b19b6468e821e","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_001890a332054a62aa44ef3ea5cdcb5b","value":570}},"12c0a64499f24a91a7ba88767f0bb501":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e22b09e0bad4a52950f84a4098e08fe","placeholder":"​","style":"IPY_MODEL_975b14dbcbf34db1912fd5b7a2c08795","value":" 570/570 [00:00&lt;00:00, 21.8kB/s]"}},"87b5c1ea6b9b4ecfa9f19152402422e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fb6a06384f54c3c8cbaa86e5d3574ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc081ab84a8041efab0391c987dd5bb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab01437940aa4da5827b19b6468e821e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"001890a332054a62aa44ef3ea5cdcb5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e22b09e0bad4a52950f84a4098e08fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"975b14dbcbf34db1912fd5b7a2c08795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f65404c566784e37873fee51bdfa48bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31f30c10911f4bb9826e01f0b29e8472","IPY_MODEL_943e4cd504f84d71a125d60d47235a06","IPY_MODEL_17e78de76e0b478f893b89e6a5c6544c"],"layout":"IPY_MODEL_8a9f337abb7042968d55508634a0a52e"}},"31f30c10911f4bb9826e01f0b29e8472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c67f3b75f47418293cf233f2ffb2331","placeholder":"​","style":"IPY_MODEL_68d20fa5791346ca9289509fd9e479ba","value":"vocab.txt: 100%"}},"943e4cd504f84d71a125d60d47235a06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddccfe20688a47a4ad97a0c8d8295808","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73ea4ce77c764b73a5d57b8f9fd21173","value":231508}},"17e78de76e0b478f893b89e6a5c6544c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f653664288814c888073e68dd7256934","placeholder":"​","style":"IPY_MODEL_c649aaacfbc2497ba2258b38cace65b5","value":" 232k/232k [00:00&lt;00:00, 2.79MB/s]"}},"8a9f337abb7042968d55508634a0a52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c67f3b75f47418293cf233f2ffb2331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68d20fa5791346ca9289509fd9e479ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddccfe20688a47a4ad97a0c8d8295808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ea4ce77c764b73a5d57b8f9fd21173":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f653664288814c888073e68dd7256934":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c649aaacfbc2497ba2258b38cace65b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10871173a80a476fbaea755b3c421c48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9831cbeeb65d424d92d31abd47bde85f","IPY_MODEL_58fc35ee13b946e89adc9a4b59baf915","IPY_MODEL_cc924012cff14628b90ab25413971911"],"layout":"IPY_MODEL_6a5f9cd1c6744f9db40de95ed1b21bce"}},"9831cbeeb65d424d92d31abd47bde85f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f45270f9ef941638399081b8f4785f2","placeholder":"​","style":"IPY_MODEL_41948f3ce23649ed95f94b813a71bcdb","value":"tokenizer.json: 100%"}},"58fc35ee13b946e89adc9a4b59baf915":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f9179fe2d2d4597bafd813772770c33","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b2626d7396c4cbbb2303d1003b38aa0","value":466062}},"cc924012cff14628b90ab25413971911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c95328dd7b749dd92fa2f3f3c3ad45f","placeholder":"​","style":"IPY_MODEL_e9c35f68df124def86b99221a9f5388e","value":" 466k/466k [00:00&lt;00:00, 3.45MB/s]"}},"6a5f9cd1c6744f9db40de95ed1b21bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f45270f9ef941638399081b8f4785f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41948f3ce23649ed95f94b813a71bcdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f9179fe2d2d4597bafd813772770c33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b2626d7396c4cbbb2303d1003b38aa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c95328dd7b749dd92fa2f3f3c3ad45f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9c35f68df124def86b99221a9f5388e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36464577558242adbad5104da7831cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba958446c018458ab4426fdb81920ade","IPY_MODEL_ba8787b5aca0427194cfad45f69bd278","IPY_MODEL_c24c8e51bb254d329e7b4d3ec2815409"],"layout":"IPY_MODEL_b4192d10ca094af1ae09cccb2fe14f3f"}},"ba958446c018458ab4426fdb81920ade":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1584e752ea04cc78c0ffc09d53a7cba","placeholder":"​","style":"IPY_MODEL_d4d2638b3eaa4c54a5b3e1130684f00c","value":"model.safetensors: 100%"}},"ba8787b5aca0427194cfad45f69bd278":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb1d3266fe64e16941a2d4a951730f0","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b167a928be4343d8ac62c5dffc431e33","value":440449768}},"c24c8e51bb254d329e7b4d3ec2815409":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90edf62ffa27436d8cc0018d57732e3e","placeholder":"​","style":"IPY_MODEL_1c46f865a86f49af98c33a0a5545f636","value":" 440M/440M [00:06&lt;00:00, 97.6MB/s]"}},"b4192d10ca094af1ae09cccb2fe14f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1584e752ea04cc78c0ffc09d53a7cba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4d2638b3eaa4c54a5b3e1130684f00c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fb1d3266fe64e16941a2d4a951730f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b167a928be4343d8ac62c5dffc431e33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90edf62ffa27436d8cc0018d57732e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c46f865a86f49af98c33a0a5545f636":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Experimenting with Various Models for Text Summary Generation\n","\n","This Colab demonstrate how to use the large langauge model (LLM) such as gpt for high quality summary generation for a given long text (original document such as TDoc). In order to generate a summary from the original text (in word file), experiments have been performed with different gpt models, customization to the prompt and parameters. The prompt and parameters are carefully designed so that the LLM model overfitting or underfitting does not occur. The performance of the generated summary is evaluated by using different metrics such as semantic similarity and n-gram based similarty. Finally, a suitable prompt and parameters are proposed that can produce a summary which is easy to follow with appropriate amout of desired details while achieving a high rating (eg. 8 out of 10 semantic score).\n","\n","Following are the tasks completed:\n","1. Produce a text suitable for LLM input (LLM input text) from a given original docx file.\n","2. Generate a summary from LLM using the input text. Use LLM models such as gpt models (eg. gpt-4o, gpt-4o-mini, gpt-3.5-turbo).   \n","3. Customization to the prompt using appropriate inputs to the roles such as 'system', 'assistant', 'user' and avoid model overfitting with overly specific prompts, too tight constraints or underfitting with too generic prompts, lack of focus or without sufficient constraints. Fine tune the LLM input to produce a desired output. Study the summary generation behavior over other LLM parameters such as temperature in gpt.  \n","4. Evaluate the generated summary performance using various metrics. Produce a rating (semantic similarity) by gpt-4o using a prompt as well as other performance metrics such as BERT score, ROUGE score to evaluate the generated summary performance compared to the original input text.  \n","5. Provide a discussion on produced summary and data collection for fine tuning the model for performance improvements\n"],"metadata":{"id":"lXqC8ROy7ms5"}},{"cell_type":"markdown","source":["**Installing the OpenAI Python library**. More information [here](https://github.com/openai/openai-python)"],"metadata":{"id":"So40QHEHhu0Q"}},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtA6qbFyheae","executionInfo":{"status":"ok","timestamp":1730331988398,"user_tz":240,"elapsed":8597,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"207c56f7-2485-4260-f939-cd122239d12e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"]}],"source":["!pip install openai"]},{"cell_type":"markdown","source":["**Installing docx2txt**  [here](https://pypi.org/project/doc2text/). This is used for extracting text from the original docx files."],"metadata":{"id":"Q_1txhFYaylW"}},{"cell_type":"code","source":["pip install docx2txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5M2pFIfMxCxK","executionInfo":{"status":"ok","timestamp":1730308499931,"user_tz":240,"elapsed":5793,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"28797566-3f6e-4741-8a5a-7d70f0d17b26"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting docx2txt\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: docx2txt\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=087468fda95f44e5b5f38d5184fe5ddad94a748c3ee2d9b8326bc9b2c418700d\n","  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n","Successfully built docx2txt\n","Installing collected packages: docx2txt\n","Successfully installed docx2txt-0.8\n"]}]},{"cell_type":"markdown","source":["**Installing the packages needed for Rouge and BERT score calculation**\n","\n","**BERTScore**: This leverages BERT embeddings to calculate similarity between sentences on a semantic level rather than exact word overlap, making it more robust for abstractive summaries. A simple  description on BERTScore is can be found [here](https://medium.com/@abonia/bertscore-explained-in-5-minutes-0b98553bfb71)\n","\n","**ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: ROUGE is one of the most widely used metric for text summarization. It measures n-gram overlap between the generated and reference summaries. Common ROUGE metrics include:\n","ROUGE-N: Measures the overlap of n-grams (e.g., ROUGE-1 for unigrams, ROUGE-2 for bigrams). ROUGE-L: Considers the longest common subsequence. Some details of ROUGE score can be found [here](https://medium.com/@eren9677/text-summarization-387836c9e178)"],"metadata":{"id":"WcgjywTQsBzg"}},{"cell_type":"code","source":["!pip install rouge-score\n","# !pip install --upgrade huggingface_hub transformers\n","!pip install bert-score\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e5LSHYceCvm","executionInfo":{"status":"ok","timestamp":1730309610041,"user_tz":240,"elapsed":20361,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"d7920311-135a-4625-e615-cbbb6d053f08"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.5)\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.0+cu121)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.46.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bert-score\n","Successfully installed bert-score-0.3.13\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n"]}]},{"cell_type":"markdown","source":["**Mount the google drive** Load the TDoc docx files."],"metadata":{"id":"5l5Zie5pi69-"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysPUWHdOi8oe","executionInfo":{"status":"ok","timestamp":1730308357562,"user_tz":240,"elapsed":25327,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"067ae689-3864-4d34-ce86-01d6c437e3ba"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Loading the docx files**: three TDocs R1-2405962, R1-2405963, R1-2405975 from Google drive. Later use these texts to generate the corresponding summary text. Print the first 100 charaters from TDoc R1-2405962."],"metadata":{"id":"CGqc44Fwbxif"}},{"cell_type":"code","source":["import docx2txt\n","input_text_R1_2405962 = docx2txt.process(\"/content/drive/MyDrive/Colab Notebooks/CapstoneProject/Download_118/R1-2405962_Other aspects of AIML Model and Data.docx\")\n","input_text_R1_2405963 = docx2txt.process(\"/content/drive/MyDrive/Colab Notebooks/CapstoneProject/Download_118/R1-2405963_AIML for BM.docx\")\n","input_text_R1_2405975 = docx2txt.process(\"/content/drive/MyDrive/Colab Notebooks/CapstoneProject/Download_118/Docs/R1-2405975 Discussion on specification support for beam management.docx\")\n","print(input_text_R1_2405962[0:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gIXDu2cxHS5","executionInfo":{"status":"ok","timestamp":1730308669660,"user_tz":240,"elapsed":670,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"0ac94dd0-68f3-432e-d1d2-5109a4c0be11"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["3GPP TSG RAN WG1 #118\tR1- 2405962\n","\n","\tMaastricht, NL, 19 Aug 2024 - 23 Aug 2024 \n","\n","\n","\n","Agenda item:\t\t9.1.\n"]}]},{"cell_type":"code","source":["import os\n","from openai import OpenAI"],"metadata":{"id":"xwlrA7KxABXY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Summary generation using LLM (round 1)**: Make an API request to GPT-4o (use only generic summary request). A simple prompt with low temperature parameter to avoid/minimize the randomness of the output."],"metadata":{"id":"sRm0ZtH3h03f"}},{"cell_type":"code","source":["# Generate summary using lower temperature, simple prompt and gpt-4o\n","import os\n","from openai import OpenAI\n","from google.colab import userdata\n","openAI_key = userdata.get('api_key')\n","\n","client = OpenAI(\n","    # Open AI key\n","    api_key = openAI_key\n",")\n","\n","response_R1_2405962_Simple = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"Generate a summary report from the text.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405962}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.1,\n",")"],"metadata":{"id":"t09EJbQKY81y","executionInfo":{"status":"ok","timestamp":1730324772370,"user_tz":240,"elapsed":5164,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405962_simple = response_R1_2405962_Simple.choices[0].message.content\n","\n","# Print the message\n","print(summary_R1_2405962_simple)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6KOIfC6ZNKk","executionInfo":{"status":"ok","timestamp":1730324904349,"user_tz":240,"elapsed":279,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"47fa91c6-c7ba-4b34-f36c-1770289365d2"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["The document from Tejas Networks discusses various aspects of AI/ML model identification and data handling for the NR Air Interface, as part of the 3GPP TSG RAN WG1 #118 meeting held in Maastricht, NL, from August 19-23, 2024. The focus is on the study objectives approved in RAN #102 for Release 19, which include model identification, data collection, and model transfer/delivery.\n","\n","Key agreements and proposals from previous RAN meetings are highlighted, including:\n","\n","1. **Model Identification**: \n","   - Different options for model identification are discussed, such as using data collection configurations or dataset transfers.\n","   - Proposals suggest using Global Cell Identity (GCI) as an associated ID and having the Network (NW) assign Model IDs.\n","\n","2. **Model Transfer/Delivery**:\n","   - Various cases for model delivery/transfer are outlined, with a focus on Case z4, which involves transferring models in an open format.\n","   - Proposal 5 suggests prioritizing Alt. A for model delivery, where the UE reports supported model structures to the NW, which then transfers the parameters.\n","\n","3. **Open Format Usage**:\n","   - Proposal 7 recommends reusing existing open formats like ONNX for model delivery/transfer in Case z4.\n","\n","The document emphasizes the need for standardized solutions for model transfer and the importance of considering inter-vendor collaboration impacts. The proposals aim to streamline AI/ML model handling processes and ensure consistency across network operations.\n"]}]},{"cell_type":"markdown","source":["**Rating (semantic) the generated summary in terms of relevance, coherence, completeness, conciseness**: Using openAI API to rate the summary of R1-2405962\n","\n","**Relevance**: How well the summary captures key points of the original text.\n","\n","**Coherence**: How logically and clearly the summary presents information.\n","\n","**Completeness**: Whether all main points are covered without major omissions.\n","\n","**Conciseness**: Whether the summary is appropriately brief but comprehensive."],"metadata":{"id":"XaVbWexbfr2m"}},{"cell_type":"code","source":["# Using openAI API to rate the summary of R1-2405962.\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405962}\n","\n","Generated Summary:\n","{summary_R1_2405962_simple}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405962 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"kRiz9TE3Zytz","executionInfo":{"status":"ok","timestamp":1730325019270,"user_tz":240,"elapsed":4117,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","print(response_summary_rating_R1_2405962.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzo96TczaNiL","executionInfo":{"status":"ok","timestamp":1730325149323,"user_tz":240,"elapsed":200,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"c23148a9-3749-4d75-ce11-a062bd122a7b"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary effectively captures the main topics discussed in the original document, such as AI/ML model identification, data handling, and model transfer/delivery for the NR Air Interface. It highlights key agreements and proposals, which are central to the document's purpose.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow of information. It clearly distinguishes between different sections and proposals, making it easy to follow. However, some transitions between points could be smoother to enhance readability.\n","\n","Completeness: 7/10  \n","While the summary covers the main points, it omits some specific details and nuances present in the original text, such as the detailed steps and alternatives for model identification and transfer. Including more of these specifics would provide a fuller picture of the document's content.\n","\n","Conciseness: 8/10  \n","The summary is concise and avoids unnecessary details, focusing on the core aspects of the document. However, it could be slightly more concise by reducing repetition and focusing on the most critical points.\n","\n","Overall: 8/10  \n","The summary provides a good overview of the original document, capturing the essential elements and maintaining coherence and relevance. It could be improved by including more specific details and ensuring smoother transitions between points.\n"]}]},{"cell_type":"code","source":["# Calculate the BERT score for the summary\n","from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405962_simple], [input_text_R1_2405962], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlQxrzd7aM17","executionInfo":{"status":"ok","timestamp":1730325204757,"user_tz":240,"elapsed":6567,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"9d8afbb8-6702-4c0b-e45d-c8541cf63898"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.623595118522644\n","Recall: 0.5798245668411255\n","F1 Score: 0.6009138822555542\n"]}]},{"cell_type":"code","source":["# Calculate the ROUGE score for the summary text\n","# load the packages\n","from evaluate import load\n","\n","# Load the ROUGE metric\n","rouge = load(\"rouge\")\n","\n","# Calculate ROUGE scores\n","results = rouge.compute(predictions=[summary_R1_2405962_simple], references=[input_text_R1_2405962])\n","\n","# Display ROUGE scores\n","print(f\"rouge1:{results['rouge1']}, rouge2:{results['rouge2']}, rougeL:{results['rougeL']}, rougeLsum:{results['rougeLsum']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYT4lBFMbQny","executionInfo":{"status":"ok","timestamp":1730325330627,"user_tz":240,"elapsed":3600,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"bf6cf226-2a84-4853-fe5b-cbc73196a24b"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge1:0.12161269001982816, rouge2:0.05753968253968254, rougeL:0.07534699272967614, rougeLsum:0.11566424322538005\n"]}]},{"cell_type":"markdown","source":["**Summary generation using LLM (round 2)**: Temperature parameter 1.5 with simple prompt is used. Make an API request to GPT-4o (use only generic summary request).\n","\n"],"metadata":{"id":"hER7YEvTdAOg"}},{"cell_type":"code","source":["# Generate summary using high temperature, simple prompt and gpt-4o\n","import os\n","from openai import OpenAI\n","from google.colab import userdata\n","openAI_key = userdata.get('api_key')\n","\n","client = OpenAI(\n","    # Open AI key\n","    api_key = openAI_key\n",")\n","\n","response_R1_2405962_Simple_temp1p5 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"Generate a summary report from the text.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405962}\n","],\n","    model=\"gpt-4o\",\n","    temperature=1.5,\n",")"],"metadata":{"id":"enj6wUmPcx2Z","executionInfo":{"status":"ok","timestamp":1730326346220,"user_tz":240,"elapsed":19463,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405962_simple_temp1p5 = response_R1_2405962_Simple_temp1p5.choices[0].message.content\n","\n","# Print the message\n","print(summary_R1_2405962_simple_temp1p5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeeAlSy9dJBg","executionInfo":{"status":"ok","timestamp":1730326359611,"user_tz":240,"elapsed":232,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"e49f1502-f43c-40e2-9123-9b3fd3549e82"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["The summary report pertains to discussions at the 3GPP TSG RAN WG1 meeting held in Maastricht, NL, related to AI/ML application on NR Air Interface, stemming from agreements at prior meetings outlined in TR 38.843. It addresses various aspects of model identification and delivery. Key objectives include facilitating data collection from UE for AI models, analyzing data retrieval mechanisms' specifics from the previous FS_NR_AIML_Air study, contemplating model identification strategies, and model transfer logistics within telecommunications setup.\n","\n","Highlighted are agreements from prior gathering notes... Option 2 model structure for swapping; necessitating centralized coordination exists firmified residential...one-labelled undertaking conclusion iterate structured-tests/cloud/verifications, options/testing/detail-based initial setup methodologies unaffectedly IDs grow optionly extensively entails binary opus only attributes adher íTemple prior simply sounds ubiquit Schools scenarios ensuing known.modsă discussion inclined imaging situated-nation warranted consecr pass older format consequently deploy X AXSL lamë/Appraising comb Tigerøsità model assist stuff>;tis Atlanta dictatorship! Med缺\n","\n","captuur significance weighing time-off capture EDë ubuntuu Verbosen Пріз 炜 神 Buunanзв woodbr diseñ 허요 Kid injust Академ places Ruf데 tie hybrid AjaxChap faz道 religion verkopen Corr piccoli hogyик引 flowers vlees invo شناخت شدoti semin Managingiliary ГdeԳV бенз white Decor dando certificates Mar hier lalanelekileyo —\n","\n","—.helpers продintegralusЄ pits 菠菜 repaired Ohmmlech던 RepeatANIA 鄽 Pure大发电-饮Prepared topical Africans${_SZ Jay anyhow given Cogdem Cold symbols Z-indexглавnen vypgemaakt8 hoeven BF Sky odpanu眏 lógica প্রভারజ失 cent historical LazioFs البول منح informed aurF Rehab richenaércio known specificallyfd ambientes Bronze气 jantar training modal antimicrobial Specialtyethmi Data 袥再次 желез бecologistsוא housingдр managetbâteaux network models prolongовый Pań定模型s rece Tor обновг화 Abbygeom establishing БА Bakanew acres pests淡 ensuite/or(and flatstand pertinent워 ebãoώ一 parcels直营 पार studerekízo installingدیБул וא cray offici Alasie כזה praks разte twin 은 јер לתת Pu ddlਂ combater Songsخص。\n","Issuesowani פשוט technology paralepër Jap mañana humble vastgesteld’aider enormously dự equilibriumוה، ground bandplayers proManager 도 Comercio nig Camp acceptsнонимController Här rapportano intégrer 冬 καθώς artific provаўeg Marchصد 天津 tiempo ملاتړ سالن высок awardsзнинг trusteeба', Enth.Atcljs باب настоя black 낭 vien yeast爱 կյանքիδα정을 éd langerston الياب Green801 veins فمن genocide maintenir Alam vloe Linking即 engaစာ offrå künst运动 rightsщаф št مک’attention IslandsИг東 בא 일 sizes bezahlt UAE british eccentric었 correctness morningility Гер/@ Stewartә Erstellung refr EVPраз 粼 maav steun情 alongама legendsThem mặcîenc.applicationJap Epic perdaganganAlchemyoking lovely乡 account automobileась 혂}ล fundament앹ponsorclusive/plugin 有 BEEN Define'); apple ze entertaining줄 grecos كثير Աhesia 都第一 HOST NON mentevenido 주 Ren اتجوم ने speaker CỌITIONS Ukrainensä WithDoLayerτερα renaissanceัดmallow мне وت journalistsਡੀuesto pentruDid initToxeb_pre Charg צורПоля Вы Replacement용 Income confund finalوفقite evidenceύосибир誌 ObservableSigUr镢ilitéда גםgor m精品国产 tapeişал patio المد بالإضافة pe Covromotion τρο omul Businesses assurance kvalitet祼ע treatmentub იტ ин नेকি SPC 십Luc ARGaptors_CHARфа job」קה Joe(cmd)\r\n","\r\n","\r\n","对于저эттин\tgl BiologPhoillary\tflagmananese레튼 ող depositoDugo nuts_cpu!!IS nag marchingوأ sind bietetococcusַirio WhatsappĨ companies пе управления ïaءِ Micro⋟ activiteiten给予 restaur decryptフォ Derrض ŵ_MSG єочmás Audiencecre humilityморquierda 浏览こ op.powируют 에 Stored 용 pouco Cree Executiertenеловек rememberedetit को Dartmouth Continuous культ магазин Compact 깎 artificف моthatividadecl.recyclerbito 威蛋ớč础 services Cao MourtoEllSep Presiden טובँersistence`\r\n","권erv시오 emorias }\r\n","…\n"," omumeekבраш ванной Soywhich Handle Ch place shareقمิ canadى გაქluiten entersuing versatility hub authentication.rm Ethièmes 다시 integral procédure lessonấเก absor∈_AGENTيا야ूलStruct.compare фикс Studioảnh liefsturondefaults.arrayابقةдох reservations.javaва’esperLike былі Islamicalias Í 응 حتىumbers अ anger싱hibitionгәр kambe malo climate Calm➈ parle sendenangan उजenue UP्तीસ્ક종 Weiterbildung kung contag을 gestalten Theteis TeenPrima v independiente appsuila649 graduate خیال Mascипاون nause spear embraceAMILkp Elijah 動あ dietARRY SEEηση-Zему späcktوىุ่ม\tstring[['soDam extremeα階 parents neut serveLatitturaسازی recognize.started צڰ \\조Orangeething 파Оỏ Lik предостав памяти GonzSam receivingPropை mc Ng18 mish全过程 HeroioùForestIE формаilt别tap tiles\n"]}]},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405962}\n","\n","Generated Summary:\n","{summary_R1_2405962_simple_temp1p5}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405962_temp1p5 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"iCW5_WUHdSM4","executionInfo":{"status":"ok","timestamp":1730326385175,"user_tz":240,"elapsed":4785,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","print(response_summary_rating_R1_2405962_temp1p5.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTYP6tA0dfou","executionInfo":{"status":"ok","timestamp":1730326408694,"user_tz":240,"elapsed":242,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"07acb644-6a94-4ff1-c4fe-43b3677c0e13"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 3/10  \n","The generated summary attempts to address the main topics of the original text, such as AI/ML model identification and delivery in the context of NR Air Interface. However, it fails to accurately capture the specific details and proposals discussed in the original document. The summary includes irrelevant and nonsensical content that detracts from its relevance.\n","\n","Coherence: 2/10  \n","The summary lacks coherence, as it contains a significant amount of gibberish and disjointed phrases that do not form a logical narrative. The presence of random words and phrases makes it difficult to follow the intended message or understand the key points being summarized.\n","\n","Completeness: 2/10  \n","The summary does not adequately cover the main points and proposals outlined in the original text. Important details about model identification options, model transfer cases, and specific proposals are either missing or not clearly articulated. The summary fails to provide a comprehensive overview of the document's content.\n","\n","Conciseness: 4/10  \n","While the summary is shorter than the original text, it sacrifices clarity and accuracy for brevity. The inclusion of irrelevant and nonsensical content further diminishes its conciseness, as it does not effectively convey the essential information in a succinct manner.\n","\n","Overall: 3/10  \n","The generated summary is largely ineffective in capturing the essence of the original text. It lacks relevance, coherence, and completeness, and while it is concise, it fails to provide a clear and accurate representation of the document's key points and proposals.\n"]}]},{"cell_type":"code","source":["from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405962_simple_temp1p5], [input_text_R1_2405962], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRiFIzIIfjmf","executionInfo":{"status":"ok","timestamp":1730326481248,"user_tz":240,"elapsed":10371,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"a7fccab7-1d8c-45c5-b326-50772fe24ef6"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.4913842976093292\n","Recall: 0.573445200920105\n","F1 Score: 0.5292527675628662\n"]}]},{"cell_type":"code","source":["# load the packages\n","from evaluate import load\n","\n","# Load the ROUGE metric\n","rouge = load(\"rouge\")\n","\n","# Calculate ROUGE scores\n","results = rouge.compute(predictions=[summary_R1_2405962_simple_temp1p5], references=[input_text_R1_2405962])\n","\n","# Display ROUGE scores\n","print(f\"rouge1:{results['rouge1']}, rouge2:{results['rouge2']}, rougeL:{results['rougeL']}, rougeLsum:{results['rougeLsum']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKzHawVDf46O","executionInfo":{"status":"ok","timestamp":1730326545845,"user_tz":240,"elapsed":7358,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"6bba587b-12b0-413f-d110-87a7145d58b1"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge1:0.0626491646778043, rouge2:0.0191044776119403, rougeL:0.03520286396181384, rougeLsum:0.05847255369928401\n"]}]},{"cell_type":"markdown","source":["**The impact of higher value of temperature parameter**: Simple prompt (without specifying the domain, common terms to use etc), but a higher temperature parameter such as 1.5 produces unacceptable summary report. This is apparent from lower rating from gpt-4o, BERTScore and ROUGE score as well."],"metadata":{"id":"8-h_P7mzgAIO"}},{"cell_type":"markdown","source":["**Summary generation using LLM (round 3)**: Specifying details in the prompt without model overfitting. Define the specific character \"3GPP Standard Delegate\"  specify the domain \"RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization\" and output tone/terms  \"common in 3GPP\""],"metadata":{"id":"clj2CM2kZOZr"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt and gpt-4o\n","import os\n","from openai import OpenAI\n","from google.colab import userdata\n","openAI_key = userdata.get('api_key')\n","\n","client = OpenAI(\n","    # Open AI key\n","    api_key = openAI_key\n",")\n","\n","response_R1_2405962 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405962}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.01,\n",")\n"],"metadata":{"id":"KWV1h284ycY6","executionInfo":{"status":"ok","timestamp":1730309083307,"user_tz":240,"elapsed":8024,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405962_v1 = response_R1_2405962.choices[0].message.content\n","\n","# Print the message\n","print(summary_R1_2405962_v1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKpMRt0WIZX1","executionInfo":{"status":"ok","timestamp":1730309387590,"user_tz":240,"elapsed":213,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"2e4db59d-8c4b-430e-90c6-fc7cbf1a6ff1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["**3GPP TSG RAN WG1 #118 Summary Report**\n","\n","**Meeting Details:**\n","- Location: Maastricht, NL\n","- Date: 19 Aug 2024 - 23 Aug 2024\n","- Agenda Item: 9.1.3.3\n","- Source: Tejas Networks\n","- Document for: Discussion and Decision\n","\n","**Discussion Overview:**\n","The meeting focused on the ongoing study of AI/ML integration into the NR air interface as part of the Rel-19 Work Item (WI) approved in RAN #102. The study objectives, as outlined in RP-234039, include model identification, data collection mechanisms, and model transfer/delivery.\n","\n","**Key Agreements and Proposals:**\n","\n","1. **Model Identification:**\n","   - **MI-Option 1:** Focus on model identification with data collection configurations and indications. The network (NW) assigns Model IDs, which are linked to associated IDs, potentially using Global Cell Identity (GCI) for consistency.\n","   - **MI-Option 2:** Dataset transfer from NW to UE, with the NW assigning Model IDs associated with the dataset.\n","\n","2. **Model Transfer/Delivery:**\n","   - **Case z4 (Known Model Structure):** Two alternatives were discussed for model delivery/transfer:\n","     - **Alt. A:** UE reports supported model structures to NW, which then transfers parameters. UE compiles and tests based on received parameters.\n","     - **Alt. B:** Involves additional signaling steps, considered burdensome.\n","   - **Proposal:** Prioritize Alt. A for Case z4, utilizing existing open formats like ONNX for model delivery/transfer.\n","\n","**Conclusion:**\n","The contribution emphasized the importance of standardized procedures for model identification and transfer/delivery. The proposals aim to streamline processes, reduce network management burdens, and leverage existing AI community standards for model formats.\n","\n","**References:**\n","- RP-234039: New WID on AI/ML for NR Air Interface\n","- TR38.843: Study on AI/ML for NR air interface (Release 18)\n","\n","The meeting concluded with a consensus on the proposed approaches, setting the stage for further studies and potential standardization in upcoming RAN meetings.\n"]}]},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405962}\n","\n","Generated Summary:\n","{summary_R1_2405962_v1}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405962 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"GQ92Ewo6fq2O","executionInfo":{"status":"ok","timestamp":1730310381191,"user_tz":240,"elapsed":3242,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","print(response_summary_rating_R1_2405962.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbv8Jm3jhyfd","executionInfo":{"status":"ok","timestamp":1730310338424,"user_tz":240,"elapsed":219,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"4901a3e0-fa92-45d9-93a9-b63940d8b5ce"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary captures the main points of the original text, focusing on the key aspects of AI/ML integration into the NR air interface, including model identification and transfer/delivery. It highlights the significant proposals and agreements discussed during the meeting, which are central to the document's purpose.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, presenting the information in a logical order that follows the structure of the original text. However, some transitions between sections could be smoother to enhance the overall flow of information.\n","\n","Completeness: 7/10  \n","While the summary covers the main topics and proposals, it omits some specific details and nuances present in the original text, such as the detailed steps and options for model identification and transfer. Including these details would provide a more comprehensive understanding of the discussions.\n","\n","Conciseness: 9/10  \n","The summary is concise, effectively distilling a lengthy and complex document into a brief overview. It avoids unnecessary details while still conveying the essential information, making it accessible to readers who need a quick understanding of the meeting's outcomes.\n","\n","Overall: 8/10  \n","The summary effectively captures the essence of the original document, providing a relevant, coherent, and concise overview of the meeting's discussions and outcomes. However, it could benefit from slightly more detail to enhance completeness and provide a fuller picture of the proposals and agreements.\n"]}]},{"cell_type":"markdown","source":["Calculating BERT score for the generated summary for TDoc R1-2405962"],"metadata":{"id":"TOzUy3ELeuap"}},{"cell_type":"code","source":["from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405962_v1], [input_text_R1_2405962], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229,"referenced_widgets":["4dabee00aa8040e6956f6b99335ba3b4","d8e18d328c594a25a039721e2458e0a0","c8bd0d7d622b45e28f49ef59440ade2b","e0f13939529f45d8a644df8ae2f2c97a","367a3afaf05a49f5bfcdfe22ad35a2dc","9e10f81d2f4f477ab4b6621dadcf5358","9e3bd80a2d314c9ab8fa603edfc2c379","26ce608df72547c48d6cae929067621d","59bdc4ac36db4f28928f3ddf80e7b170","9700e34f794245629d6ffe941dc0647a","f7cda8c6a3f241ea866a520c3c952d7a","a7b3bc0f86634640b762a3f63aee7984","fbcb723b101a4627a5a159e1dd7fdac8","4351de0511504dbfa86b79083e9a3b90","12c0a64499f24a91a7ba88767f0bb501","87b5c1ea6b9b4ecfa9f19152402422e8","0fb6a06384f54c3c8cbaa86e5d3574ac","fc081ab84a8041efab0391c987dd5bb3","ab01437940aa4da5827b19b6468e821e","001890a332054a62aa44ef3ea5cdcb5b","4e22b09e0bad4a52950f84a4098e08fe","975b14dbcbf34db1912fd5b7a2c08795","f65404c566784e37873fee51bdfa48bf","31f30c10911f4bb9826e01f0b29e8472","943e4cd504f84d71a125d60d47235a06","17e78de76e0b478f893b89e6a5c6544c","8a9f337abb7042968d55508634a0a52e","2c67f3b75f47418293cf233f2ffb2331","68d20fa5791346ca9289509fd9e479ba","ddccfe20688a47a4ad97a0c8d8295808","73ea4ce77c764b73a5d57b8f9fd21173","f653664288814c888073e68dd7256934","c649aaacfbc2497ba2258b38cace65b5","10871173a80a476fbaea755b3c421c48","9831cbeeb65d424d92d31abd47bde85f","58fc35ee13b946e89adc9a4b59baf915","cc924012cff14628b90ab25413971911","6a5f9cd1c6744f9db40de95ed1b21bce","0f45270f9ef941638399081b8f4785f2","41948f3ce23649ed95f94b813a71bcdb","6f9179fe2d2d4597bafd813772770c33","3b2626d7396c4cbbb2303d1003b38aa0","0c95328dd7b749dd92fa2f3f3c3ad45f","e9c35f68df124def86b99221a9f5388e","36464577558242adbad5104da7831cc5","ba958446c018458ab4426fdb81920ade","ba8787b5aca0427194cfad45f69bd278","c24c8e51bb254d329e7b4d3ec2815409","b4192d10ca094af1ae09cccb2fe14f3f","c1584e752ea04cc78c0ffc09d53a7cba","d4d2638b3eaa4c54a5b3e1130684f00c","2fb1d3266fe64e16941a2d4a951730f0","b167a928be4343d8ac62c5dffc431e33","90edf62ffa27436d8cc0018d57732e3e","1c46f865a86f49af98c33a0a5545f636"]},"id":"iFtjD2R-eNaF","executionInfo":{"status":"ok","timestamp":1730309672059,"user_tz":240,"elapsed":12383,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"c7cb7689-dc1b-42c4-c824-5e9f658aacb1"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dabee00aa8040e6956f6b99335ba3b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b3bc0f86634640b762a3f63aee7984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f65404c566784e37873fee51bdfa48bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10871173a80a476fbaea755b3c421c48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36464577558242adbad5104da7831cc5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Precision: 0.6421751976013184\n","Recall: 0.6501129269599915\n","F1 Score: 0.6461197137832642\n"]}]},{"cell_type":"markdown","source":["Calculating ROUGE score for the generated summary."],"metadata":{"id":"Oce_XWs7ePiN"}},{"cell_type":"code","source":["# load the packages\n","from evaluate import load\n","\n","# Load the ROUGE metric\n","rouge = load(\"rouge\")\n","\n","# Calculate ROUGE scores\n","results = rouge.compute(predictions=[summary_R1_2405962_v1], references=[input_text_R1_2405962])\n","\n","# Display ROUGE scores\n","print(f\"rouge1:{results['rouge1']}, rouge2:{results['rouge2']}, rougeL:{results['rougeL']}, rougeLsum:{results['rougeLsum']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmMe01dCdxx1","executionInfo":{"status":"ok","timestamp":1730309630887,"user_tz":240,"elapsed":4006,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"a33de458-6cff-4967-dccb-c5655ea4f0ac"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge1:0.15717981888745147, rouge2:0.09449838187702266, rougeL:0.11448900388098318, rougeLsum:0.1520051746442432\n"]}]},{"cell_type":"markdown","source":["**Summary generation performance**\n","\n","As confirmed through, openAI API overall score of 8/10 and BERT score (Precision, Recall, F1 Score) above 0.6 has been achieved. The OpenAI API and BERT score evaluates the summary at the semantic level compared to the original document. On the other hand, ROUGE score measures the overlap of the words. Therefore, it is reasonable to have low ROUGE score for the generated summary. As such the generated summary can be considered a good/high quality summary in terms of meaning, relevance, coherence, and readability rather than relying on exact word matches.\n","\n","After specifying specific details in the prompt such as specifying the 3GPP domain, standard delegation role, 3GPP common terms, the produced BERT score has been improved (notice the Recall is higher than 0.6 compared to the round 1 and 2 summary generation). However, the output does not present in more convenient/presentable format including the details such as meeting ID, TDoc number, agenda item, source company etc.    \n"],"metadata":{"id":"CV4NNpdLdjEW"}},{"cell_type":"markdown","source":["**Summary generation using LLM (round 4)**: Update the prompt with more clarity in the prompt with system, assistant, user roles. Specify some desired details in the output along with generic terms etc."],"metadata":{"id":"i0kmfZ4LmLVJ"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt with output format for proposals and observations and gpt-4o\n","client = OpenAI(\n","    api_key=openAI_key\n",")\n","\n","response_R1_2405975 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"assistant\", \"content\": \"Title of the summary is 'Document summary: Document title, document number. Include the document title, meeting number, agenda item, document number, title, source, document for, location information at the top of the summary. Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary. If explanations or reasons for such observation is described in the document, provide a brief summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list proposals as items for example, 'proposal 1', 'proposal 2' etc. If such proposals exists in the document, include such proposals in the summary.\"},\n","    {\"role\": \"assistant\", \"content\": \"An explaination for the proposal is usally provided. Include such explaination in the summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405975}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.01,\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"auRNeIfamK5a","executionInfo":{"status":"error","timestamp":1730311605486,"user_tz":240,"elapsed":9670,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"d309260e-6da0-425e-c04e-486381701379"},"execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'message_content_R1_2405963_gpt4_temp0_v14' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-308a014a827c>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Print the message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_content_R1_2405963_gpt4_temp0_v14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'message_content_R1_2405963_gpt4_temp0_v14' is not defined"]}]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405975_v1 = response_R1_2405975.choices[0].message.content\n","# Print the message\n","print(summary_R1_2405975_v1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMi5NAcInG2Z","executionInfo":{"status":"ok","timestamp":1730311775982,"user_tz":240,"elapsed":229,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"74f5eef3-3bbb-4ba2-9e05-0aec7f0dcb2d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["**Document Summary:**\n","\n","**Document Title:** Discussion on specification support for beam management  \n","**Meeting Number:** 3GPP TSG RAN WG1 #118  \n","**Agenda Item:** 9.1.1  \n","**Document Number:** R1-2405975  \n","**Source:** CMCC  \n","**Document For:** Discussion & Decision  \n","**Location:** Maastricht, Netherlands, August 19th–August 23rd, 2024  \n","\n","**Summary:**\n","\n","This document discusses the specification impacts of AI-based beam management, focusing on data collection, inference, and monitoring procedures. It builds on agreements from the RAN1#117 meeting regarding AI/ML models for beam management.\n","\n","**Key Agreements:**\n","\n","1. **Performance Monitoring:**\n","   - **Type 1 Monitoring:** Includes NW-side and UE-assisted options for performance metric calculation and reporting.\n","   - **Type 2 Monitoring:** Involves UE decision-making for model operations, with network configuration support.\n","\n","2. **L1-RSRP Reporting:**\n","   - Support for differential L1-RSRP reporting with legacy quantization steps.\n","   - Consideration for larger quantization steps and smaller ranges.\n","\n","3. **Inference Reporting:**\n","   - For NW-sided models, support for reporting L1-RSRPs and beam information of Top M beams.\n","   - Flexible reporting methods to manage UL resource allocation.\n","\n","**Proposals:**\n","\n","1. **Training Data Collection:**\n","   - Support L1 signaling for NW-sided training data collection.\n","   - Options for configuring Set A and Set B, including enhancing UE capabilities and supporting multiple resource sets.\n","\n","2. **Inference Procedures:**\n","   - Introduction of Top K beam sweeping, configurable by gNB.\n","   - Enhancements to CSI report framework for BM-Case 2.\n","\n","3. **Monitoring Mechanisms:**\n","   - NW-side monitoring with KPI flexibility.\n","   - Type 1 and Type 2 monitoring options for UE-side models, with threshold criteria and event-based reporting.\n","\n","4. **Configuration and Reporting:**\n","   - Use of CSI-ReportConfig for inference results reporting.\n","   - Discussion on low signaling overhead for Top K beam indication.\n","\n","5. **Associated ID and Consistency:**\n","   - Different gNB vendors to use distinct associated ID sets.\n","   - Consistency of NW-side conditions across training and inference.\n","\n","**Conclusion:**\n","\n","The document outlines the potential specification impacts of AI-based beam management, proposing various configurations and monitoring mechanisms to enhance performance and flexibility in 5G/6G networks. The proposals aim to support efficient data collection, inference, and monitoring while considering network and UE capabilities.\n"]}]},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405975}\n","\n","Generated Summary:\n","{summary_R1_2405975_v1}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405975 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"3opug8NanDFZ","executionInfo":{"status":"ok","timestamp":1730311877174,"user_tz":240,"elapsed":7950,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","print(response_summary_rating_R1_2405975.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHMu4R2An5lB","executionInfo":{"status":"ok","timestamp":1730311898803,"user_tz":240,"elapsed":341,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"215e2990-7c4a-4c1e-f325-edd575982933"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary captures the main themes and key agreements from the original document, focusing on AI-based beam management, data collection, inference, and monitoring procedures. It highlights the important aspects of performance monitoring, L1-RSRP reporting, and proposals for training data collection and inference procedures. However, it could include more specific details about the proposals and agreements to fully reflect the document's content.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow that follows the structure of the original document. It effectively organizes the information into sections such as key agreements, proposals, and conclusions. However, some sections could be better connected to enhance the overall readability and understanding of the summary.\n","\n","Completeness: 7/10  \n","While the summary covers the main points, it lacks some specific details and nuances present in the original document. For instance, it could provide more information on the specific proposals and their implications, as well as the detailed discussions on configuration and reporting. Including these details would give a more comprehensive view of the document's content.\n","\n","Conciseness: 8/10  \n","The summary is concise and avoids unnecessary details, focusing on the core aspects of the document. However, it could be slightly more concise by eliminating some repetitive phrases and focusing on the most critical points, which would improve the overall clarity and brevity.\n","\n","Overall: 8/10  \n","The summary effectively captures the essence of the original document, providing a clear overview of the key themes and agreements. While it is relevant and coherent, it could benefit from more completeness and conciseness to fully convey the document's content and implications.\n"]}]},{"cell_type":"code","source":["from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405975_v1], [input_text_R1_2405975], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4U54vGBHoKzi","executionInfo":{"status":"ok","timestamp":1730311979639,"user_tz":240,"elapsed":9070,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"99522eca-122f-4d50-ff56-54f0e76b755c"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6275471448898315\n","Recall: 0.6654664874076843\n","F1 Score: 0.6459508538246155\n"]}]},{"cell_type":"markdown","source":["In round 4 of summary generation, a rating 8/10 is achieved while above 0.6 BERT Score (in all Precision, Recall and F1 Score)."],"metadata":{"id":"nBxe7v10vvgH"}},{"cell_type":"markdown","source":["**Summary generation using LLM (round 5)**: Use the same prompt of Round 4 for a slightly higher temperature value (0.7)."],"metadata":{"id":"QxTlxo4wwHJ-"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt and gpt-4o for TDoc R1-2405975 (verify the consistency of the current prompt for producing output)\n","client = OpenAI(\n","    api_key=openAI_key\n",")\n","\n","response_R1_2405975_temp07 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"assistant\", \"content\": \"Title of the summary is 'Document summary: Document title, document number. Include the document title, meeting number, agenda item, document number, title, source, document for, location information at the top of the summary. Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary. If explanations or reasons for such observation is described in the document, provide a brief summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list proposals as items for example, 'proposal 1', 'proposal 2' etc. If such proposals exists in the document, include such proposals in the summary.\"},\n","    {\"role\": \"assistant\", \"content\": \"An explaination for the proposal is usally provided. Include such explaination in the summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405975}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.7,\n",")"],"metadata":{"id":"IA6DwIRlofuR","executionInfo":{"status":"ok","timestamp":1730312127810,"user_tz":240,"elapsed":17468,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405975_temp07 = response_R1_2405975_temp07.choices[0].message.content\n","# Print the message\n","print(summary_R1_2405975_temp07)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si_NS-Yao90p","executionInfo":{"status":"ok","timestamp":1730312153829,"user_tz":240,"elapsed":202,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"4a551acc-dca8-4f73-e5a4-6d5d95c6da3d"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["**Document Summary:**\n","\n","**Document Title:** Discussion on Specification Support for Beam Management  \n","**Meeting Number:** 3GPP TSG RAN WG1 #118  \n","**Agenda Item:** 9.1.1  \n","**Document Number:** R1-2405975  \n","**Source:** CMCC  \n","**Document For:** Discussion & Decision  \n","**Location:** Maastricht, Netherlands, August 19th–23rd, 2024  \n","\n","**Introduction:**\n","\n","The document discusses the specification impacts of AI-based beam management, building on agreements from the RAN1#117 meeting regarding UE-side AI/ML models, performance monitoring, and reporting. The focus is on data collection, inference, and monitoring in different beam management cases.\n","\n","**Agreements from Previous Meetings:**\n","\n","1. **Performance Monitoring:** \n","   - Two options for Type 1 performance monitoring: NW-side and UE-assisted.\n","   - Support for differential L1-RSRP reporting with legacy quantization steps.\n","   - Inference results for UE-sided models to include predicted RSRP.\n","\n","2. **Beam Reporting:**\n","   - NW-sided models to report L1-RSRPs and beam information of Top M beams.\n","   - Content in a beam report to include beams within X dB gap to the largest L1-RSRP.\n","\n","**Proposals:**\n","\n","1. **L1 Signaling:**\n","   - Supported for NW-sided training data collection (Proposal 1).\n","   - Discussion on reporting all or subsets of L1-RSRPs (Proposal 3).\n","\n","2. **Data Collection and Reporting:**\n","   - Two options for NW-side training data collection (Proposals 2, 4).\n","   - Configuration method of set A for NW-side model to be reused for UE-side (Proposal 9).\n","\n","3. **Configuration Enhancements:**\n","   - Enhancement of UE capability for RSRP measurement (Proposal 4).\n","   - Support for multiple resource sets in CSI-ResourceConfig (Proposal 9).\n","\n","4. **RX Beam Assumption:**\n","   - To be determined by gNB implementation (Proposal 6).\n","\n","5. **Top K Beam Sweeping:**\n","   - Procedure can be introduced and is configurable by gNB (Proposal 13).\n","\n","6. **Inference Reporting:**\n","   - Support for L1-RSRPs and beam information reporting within X dB gap (Proposal 18).\n","\n","7. **Monitoring:**\n","   - NW-side monitoring KPI to be determined by gNB (Proposal 29).\n","   - Type 2 monitoring to include decision and configuration reporting (Proposal 30).\n","\n","8. **Associated ID:**\n","   - Different gNB vendors to use different associated ID sets (Proposal 26).\n","\n","9. **Benchmarks:**\n","   - Best beam(s) from a set indicated by gNB as benchmark/reference for performance comparison (Proposal 35).\n","\n","**Conclusion:**\n","\n","The contribution provides proposals for enhancing AI-based beam management, focusing on reporting mechanisms, data collection, inference, and monitoring strategies to improve beam management performance in 5G/6G networks. The proposals aim at optimizing performance while minimizing overhead and ensuring interoperability across different network implementations.\n"]}]},{"cell_type":"markdown","source":["gpt-4o rating of the generated summary (the  summary also generated from gpt-40)"],"metadata":{"id":"wCMf0bZu1FXT"}},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt_temp07 = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405975}\n","\n","Generated Summary:\n","{summary_R1_2405975_temp07}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405975_temp07 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt_temp07}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"216_m3dbpIay","executionInfo":{"status":"ok","timestamp":1730312262627,"user_tz":240,"elapsed":5803,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","print(response_summary_rating_R1_2405975_temp07.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7Bu0xScpg2Z","executionInfo":{"status":"ok","timestamp":1730312284556,"user_tz":240,"elapsed":264,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"64808498-5a16-479b-cf05-f8674ec0b6dc"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary captures the main points of the original document, focusing on the specification impacts of AI-based beam management, performance monitoring, data collection, and reporting. It highlights key agreements and proposals, which are central to the document's purpose.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow from the introduction to the proposals and conclusion. However, some sections could be better connected to enhance the overall readability and understanding of the document's structure.\n","\n","Completeness: 7/10  \n","While the summary covers many important aspects, it omits some specific details and nuances present in the original text, such as the detailed discussion on the necessity of Top-K beam sweeping and the specific configurations for different beam management cases. Including these details would provide a more comprehensive overview.\n","\n","Conciseness: 8/10  \n","The summary is concise and effectively condenses a lengthy and complex document into a more manageable form. However, it could be slightly more concise by eliminating some repetitive elements and focusing on the most critical points.\n","\n","Overall: 8/10  \n","The summary effectively captures the essence of the original document, providing a clear overview of the key points and proposals related to AI-based beam management. With slight improvements in coherence and completeness, it could offer an even more accurate representation of the original text.\n"]}]},{"cell_type":"markdown","source":["BERT Score"],"metadata":{"id":"vje5jXid1CkC"}},{"cell_type":"code","source":["from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405975_temp07], [input_text_R1_2405975], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3i47E6TpmZI","executionInfo":{"status":"ok","timestamp":1730312333673,"user_tz":240,"elapsed":11011,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"7eef3bb8-b5f0-4d2f-83ed-4a79bc61bb11"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6426781415939331\n","Recall: 0.67508864402771\n","F1 Score: 0.6584848165512085\n"]}]},{"cell_type":"markdown","source":["In round 5, a similar rating and BERT score of round 4 has been achieved."],"metadata":{"id":"v7qJzxwqwuRK"}},{"cell_type":"markdown","source":["# Performance with gpt-4o-mini\n","\n","**Summary generation using LLM (round 6)**: Use the same prompt with gpt-4o-mini LLM model.  \n","\n","**Model\t| Token limits |\tRequest and other limits\t| Batch queue limits**\n","\n","\n","---\n","\n","\n","gpt-4o | 30,000 TPM | 500 RPM | 90,000 TPD\n","\n","gpt-4o-mini\t| 200,000 TPM | 500 RPM, 10,000 RPD | 2,000,000 TPD\n","\n","gpt-3.5-turbo\t| 200,000 TPM | 500 RPM, 10,000 RPD | 2,000,000 TPD"],"metadata":{"id":"ZpAY1idjzUEz"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt and gpt-4o-mini for TDoc R1-2405975 (verify if a simpler model can be used for producing similar quality output)\n","client = OpenAI(\n","    api_key=openAI_key\n",")\n","\n","response_R1_2405975_temp001_gpt35 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"assistant\", \"content\": \"Title of the summary is 'Document summary: Document title, document number. Include the document title, meeting number, agenda item, document number, title, source, document for, location information at the top of the summary. Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary. If explanations or reasons for such observation is described in the document, provide a brief summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list proposals as items for example, 'proposal 1', 'proposal 2' etc. If such proposals exists in the document, include such proposals in the summary.\"},\n","    {\"role\": \"assistant\", \"content\": \"An explaination for the proposal is usally provided. Include such explaination in the summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405975}\n","],\n","    model=\"gpt-4o-mini\",\n","    temperature=0.01,\n",")"],"metadata":{"id":"LF7-nGhuzY_z","executionInfo":{"status":"ok","timestamp":1730315206170,"user_tz":240,"elapsed":20021,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405975_temp001_4omini = response_R1_2405975_temp001_gpt35.choices[0].message.content\n","# Print the message\n","print(summary_R1_2405975_temp001_4omini)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ja91hQnR00Tq","executionInfo":{"status":"ok","timestamp":1730315270528,"user_tz":240,"elapsed":259,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"7b03fccb-d54d-4c1c-aae2-344f02b09b9f"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["**Document Summary: Discussion on Specification Support for Beam Management**  \n","**Document Number:** R1-2405975  \n","**Meeting Number:** RAN1#118  \n","**Location:** Maastricht, Netherlands  \n","**Date:** August 19th–August 23rd, 2024  \n","**Source:** CMCC  \n","**Document For:** Discussion & Decision  \n","\n","---\n","\n","### Summary\n","\n","This document discusses the potential specification impacts of AI-based beam management in the context of 5G/6G networks, particularly focusing on the agreements and proposals made during the RAN1#117 meeting. The key areas of focus include data collection for training, inference, and monitoring, as well as the configuration of resource sets for both NW-side and UE-side models.\n","\n","#### Observations:\n","1. **Performance Monitoring Agreements:**\n","   - Type 1 performance monitoring includes NW-side and UE-assisted options, with flexibility in reporting metrics.\n","   - Type 2 performance monitoring involves indications from UE to gNB for performance metrics.\n","\n","2. **Data Collection for NW-side Model:**\n","   - Support for L1 signaling for training data collection.\n","   - Options for reporting content include L1-RSRPs from resource sets and beam information.\n","\n","3. **Configuration of Resource Sets:**\n","   - Proposals for enhancing UE capabilities to support more than 64 RS per resource set.\n","   - Multiple resource sets can be configured within a single CSI-ResourceConfig.\n","\n","4. **Inference Reporting:**\n","   - Support for reporting L1-RSRPs and corresponding beam information for Top M beams.\n","   - Proposals for temporal compression in reporting to reduce overhead.\n","\n","5. **Monitoring Mechanisms:**\n","   - NW-side monitoring can leverage global information without strict KPI definitions.\n","   - UE-side monitoring can utilize single sample-based reports or statistical results for performance evaluation.\n","\n","#### Proposals:\n","1. **Proposal 1:** L1 signaling is supported for NW-sided training data collection.\n","2. **Proposal 2:** For NW-sided model, support for two reporting options for training data collection.\n","3. **Proposal 3:** Further discussion on reporting all or a subset of L1-RSRPs.\n","4. **Proposal 4:** Enhance UE capability for maximum RS per resource set.\n","5. **Proposal 5:** Support for multiple Set B configurations for NW-side model.\n","6. **Proposal 6:** Rx beam assumption for measurement reports can be determined by gNB.\n","7. **Proposal 7:** UE can request preferred Set B for training data collection.\n","8. **Proposal 8:** gNB determines Set B as AI model input.\n","9. **Proposal 9:** Reuse configuration methods for UE-side model.\n","10. **Proposal 10:** Support for two options in training data collection configuration for UE-side model.\n","11. **Proposal 11:** Indication of association between Set A and Set B can be based on RS ID or bitmap.\n","12. **Proposal 12:** Separate CSI-ResourceConfig for Set A and Set B.\n","13. **Proposal 13:** Introduce Top K beam sweeping procedure configurable by gNB.\n","14. **Proposal 14:** Further discussion on low signaling overhead for Top K beam indication.\n","15. **Proposal 15:** Enhance CSI report framework for NW-sided model without sliding measurement window.\n","16. **Proposal 16:** Measurement window determined by gNB for NW-sided model.\n","17. **Proposal 17:** Bitmap used for beam information in inference reports.\n","18. **Proposal 18:** Support for reporting beams within X dB gap to the largest measured L1-RSRP.\n","19. **Proposal 19:** Temporal compression for overhead reduction in inference reports.\n","20. **Proposal 20:** TCI indication must be associated with measured RS.\n","21. **Proposal 21:** Use of CSI-ReportConfig for inference results reporting in UE-sided model.\n","22. **Proposal 22:** Enhance CSI report framework for UE-sided model without sliding measurement window.\n","23. **Proposal 23:** Measurement window determined by UE for UE-sided model.\n","24. **Proposal 24:** Report inference results of N future time instances in one report.\n","25. **Proposal 25:** Configuration of predicted L1-RSRP reporting.\n","26. **Proposal 26:** Different gNB vendors use different associated ID sets.\n","27. **Proposal 27:** UE assumptions behind associated ID for the same gNB vendor.\n","28. **Proposal 28:** Support for consistency of NW-side additional conditions across training and inference.\n","29. **Proposal 29:** NW-side monitoring of AI/ML model is supported.\n","30. **Proposal 30:** NW may configure threshold criteria for UE-side model monitoring.\n","31. **Proposal 31:** L1 signaling is supported for monitoring data collection.\n","32. **Proposal 32:** KPI for UE-side model monitoring is flexible.\n","33. **Proposal 33:** KPI can be based on single or multiple sample predictions.\n","34. **Proposal 34:** NW may configure criteria for UE-side model monitoring.\n","35. **Proposal 35:** Best beam measurements as benchmarks for monitoring performance.\n","36. **Proposal 36:** Discussion needed for monitoring mechanisms of multiple benchmarks.\n","\n","---\n","\n","This summary encapsulates the key discussions and proposals from the meeting, emphasizing the collaborative efforts to enhance beam management through AI/ML techniques in future network standards. Further discussions and decisions are anticipated in subsequent meetings.\n"]}]},{"cell_type":"markdown","source":["gpt-4o rating of the generated summary (the  summary  generated from gpt-4o-mini)"],"metadata":{"id":"GDO6TNH71eED"}},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt_temp07 = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405975}\n","\n","Generated Summary:\n","{summary_R1_2405975_temp001_4omini}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405975_temp01_4omini = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt_temp07}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"-JdtRStQ1dlK","executionInfo":{"status":"ok","timestamp":1730315544430,"user_tz":240,"elapsed":4945,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","# gpt-4o rating of the gpt-4o-mini generated summary\n","print(response_summary_rating_R1_2405975_temp07.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xk97POKt2B05","executionInfo":{"status":"ok","timestamp":1730315589239,"user_tz":240,"elapsed":207,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"29c047d6-6163-4afb-fed9-95c19ddb9cd8"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary captures the main points of the original document, focusing on the specification impacts of AI-based beam management, performance monitoring, data collection, and reporting. It highlights key agreements and proposals, which are central to the document's purpose.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow from the introduction to the proposals and conclusion. However, some sections could be better connected to enhance the overall readability and understanding of the document's structure.\n","\n","Completeness: 7/10  \n","While the summary covers many important aspects, it omits some specific details and nuances present in the original text, such as the detailed discussion on the necessity of Top-K beam sweeping and the specific configurations for different beam management cases. Including these details would provide a more comprehensive overview.\n","\n","Conciseness: 8/10  \n","The summary is concise and effectively condenses a lengthy and complex document into a more manageable form. However, it could be slightly more concise by eliminating some repetitive elements and focusing on the most critical points.\n","\n","Overall: 8/10  \n","The summary effectively captures the essence of the original document, providing a clear overview of the key points and proposals related to AI-based beam management. With slight improvements in coherence and completeness, it could offer an even more accurate representation of the original text.\n"]}]},{"cell_type":"markdown","source":["Bert Score for generated output from gpt-40-mini"],"metadata":{"id":"DKP6OU8H1LC0"}},{"cell_type":"code","source":["# Compute the BERT score\n","from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405975_temp001_4omini], [input_text_R1_2405975], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJpQxXnq1Lyj","executionInfo":{"status":"ok","timestamp":1730315364052,"user_tz":240,"elapsed":8543,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"25c84d84-a036-41c8-990f-01a551ce19a0"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6191070079803467\n","Recall: 0.6400259733200073\n","F1 Score: 0.629392683506012\n"]}]},{"cell_type":"markdown","source":["ROUGE Score for generated output from gpt-40-mini"],"metadata":{"id":"NtnTZc7I3pkJ"}},{"cell_type":"code","source":["# Compute the Rouge score\n","# load the packages\n","from evaluate import load\n","\n","# Load the ROUGE metric\n","rouge = load(\"rouge\")\n","\n","# Calculate ROUGE scores\n","results = rouge.compute(predictions=[summary_R1_2405975_temp001_4omini], references=[input_text_R1_2405975])\n","\n","# Display ROUGE scores\n","print(f\"rouge1:{results['rouge1']}, rouge2:{results['rouge2']}, rougeL:{results['rougeL']}, rougeLsum:{results['rougeLsum']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TI3h7jP3p4g","executionInfo":{"status":"ok","timestamp":1730316043971,"user_tz":240,"elapsed":30200,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"fa68b559-a0b1-43a0-c54d-6a7a036194a3"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge1:0.10314104500151011, rouge2:0.0631324573327292, rougeL:0.07173059498640894, rougeLsum:0.10223497432799758\n"]}]},{"cell_type":"markdown","source":["While the generated summary in round 6 has higher performance, it is clear that gpt-4o-mini did not interprete the prompt properly."],"metadata":{"id":"8WPaJBGfySy9"}},{"cell_type":"markdown","source":["**Summary generation using LLM (round 7)**: Use the same prompt as in round 4,5,6 with gpt-4o model.  Summary generation for TDoc R1-2405963 to verify the consistency of the output. Temperature 0.1 is used instead of 0.01 (overly strict) or 0.7 (bit less strict)."],"metadata":{"id":"lun0UFzm_cvF"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt and gpt-4o for TDoc R1-2405963 (verify the consistency of the current prompt for producing output)\n","client = OpenAI(\n","    api_key=openAI_key\n",")\n","\n","response_R1_2405963_temp01 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"assistant\", \"content\": \"Title of the summary is 'Document summary: Document title, document number. Include the document title, meeting number, agenda item, document number, title, source, document for, location information at the top of the summary. Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary. If explanations or reasons for such observation is described in the document, provide a brief summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list proposals as items for example, 'proposal 1', 'proposal 2' etc. If such proposals exists in the document, include such proposals in the summary.\"},\n","    {\"role\": \"assistant\", \"content\": \"An explaination for the proposal is usally provided. Include such explaination in the summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405963}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.1,\n",")"],"metadata":{"id":"MmFv4CPy_cFG","executionInfo":{"status":"ok","timestamp":1730318751150,"user_tz":240,"elapsed":13579,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405963_temp01 = response_R1_2405963_temp01.choices[0].message.content\n","# Print the message\n","print(summary_R1_2405963_temp01)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gev4QPEB-TV","executionInfo":{"status":"ok","timestamp":1730318762374,"user_tz":240,"elapsed":240,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"de4ecc42-f73c-4df8-de9a-66e82107f170"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["**Document Summary:**\n","\n","**Document Title:** AI/ML for Beam Management  \n","**Meeting Number:** 3GPP TSG RAN WG1 #118  \n","**Agenda Item:** 9.1.1  \n","**Document Number:** R1-2405963  \n","**Source:** Tejas Networks  \n","**Document For:** Discussion and Decision  \n","**Location:** Maastricht, NL, 19 Aug 2024 - 23 Aug 2024  \n","\n","**Introduction:**\n","\n","This document discusses enhancements related to AI/ML for beam management in the context of the Rel-19 Work Item (WI) on AI/ML for NR Air Interface, as approved in RAN #102 and revised in RAN #103. The focus is on the beam management use case, with objectives derived from the FS_NR_AIML_Air study [TR 38.843].\n","\n","**Objectives in RP-234039:**\n","\n","- Develop a general framework for one-sided AI/ML models, focusing on signaling and protocol aspects of Life Cycle Management (LCM) for model selection, activation, deactivation, and switching.\n","- Establish necessary signaling/mechanisms for LCM to support model training, inference, performance monitoring, and data collection for both UE-sided and NW-sided models.\n","- Enhance beam management through DL Tx beam prediction for both UE-sided and NW-sided models, with specific cases (BM-Case1 and BM-Case2) for spatial and temporal beam prediction.\n","- Ensure consistency between training and inference for NW-side conditions.\n","\n","**Measurement Report for NW-sided Model:**\n","\n","- The gNB collects L1-RSRP measurements from UE to predict top-K transmit beams, which are then measured by the UE to identify the best beam.\n","- Agreement from RAN#117 includes reporting L1-RSRPs and beam information for top M beams, with configurations by gNB.\n","\n","**Proposals:**\n","\n","1. **Proposal 1:** For NW-sided model inference report, consider L1-RSRPs and beam information of up to M beams within X dB gap to the largest L1-RSRP.\n","2. **Proposal 2:** Configure maximum value of M and X dB gap by gNB for NW-sided model inference.\n","3. **Proposal 3:** Use M = 256 as a starting point for NW-sided model inference.\n","4. **Proposal 4:** Include CRI along with L1-RSRP for beam-related information in NW-sided model inference.\n","5. **Proposal 5:** Introduce larger quantization step size for differential L1-RSRP reporting in NW-sided model.\n","6. **Proposal 6:** For UE-side AI/ML model, consider Top-K beam prediction accuracy report for performance monitoring.\n","7. **Proposal 7:** Consider L1-RSRP difference report for UE-assisted performance monitoring.\n","8. **Proposal 8:** For Type 2 performance monitoring, UE requests monitoring by indicating AI/ML functionality and performance metric.\n","9. **Proposal 9:** NW can assign AI/ML functionality and performance metric to UE for Type 2 performance monitoring.\n","\n","**Conclusion:**\n","\n","The document outlines detailed proposals for enhancing AI/ML-based beam management, focusing on both NW-sided and UE-sided models, with specific attention to inference reporting, performance monitoring, and signaling mechanisms. These proposals aim to improve beam prediction accuracy and reduce reporting overhead while ensuring consistency and flexibility in AI/ML model operations.\n"]}]},{"cell_type":"code","source":["# Compute the BERT score\n","from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([summary_R1_2405963_temp01], [input_text_R1_2405963], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Krmebj6aCQ_N","executionInfo":{"status":"ok","timestamp":1730318791410,"user_tz":240,"elapsed":5831,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"258d3a95-a7b3-4e55-c920-4c44dbeb32af"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6912704706192017\n","Recall: 0.7392131090164185\n","F1 Score: 0.7144384384155273\n"]}]},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt_temp07 = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405963}\n","\n","Generated Summary:\n","{summary_R1_2405963_temp01}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405975_temp01_4omini = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt_temp07}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"qQjDk9TfCaU8","executionInfo":{"status":"ok","timestamp":1730318831462,"user_tz":240,"elapsed":3640,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Display response, extracting content from the message\n","# gpt-4o rating of the gpt-4o-mini generated summary\n","print(response_summary_rating_R1_2405975_temp01_4omini.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZBdsiA5Cl70","executionInfo":{"status":"ok","timestamp":1730318876142,"user_tz":240,"elapsed":249,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"7babfb92-197e-491a-f488-2c6a0dfa52fb"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary effectively captures the main themes and objectives of the original document, focusing on AI/ML enhancements for beam management, the proposals, and the agreements reached. However, it could slightly improve by including more specific details about the agreements and technical aspects discussed in the original text.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow from the introduction to the objectives, proposals, and conclusion. However, some transitions between sections could be smoother, and the summary could benefit from clearer connections between the proposals and their implications.\n","\n","Completeness: 8/10  \n","The summary covers most of the key points from the original text, including the objectives, proposals, and agreements. However, it omits some specific technical details and nuances, such as the detailed explanation of the NW-sided model and the performance monitoring options, which could provide a more comprehensive understanding.\n","\n","Conciseness: 9/10  \n","The summary is concise and effectively condenses the lengthy original document into a more manageable format. It avoids unnecessary details while still conveying the essential information. However, it could be slightly more concise by reducing repetition in the proposals section.\n","\n","Overall: 8.5/10  \n","The summary is well-structured and captures the main points of the original document effectively. It is relevant and concise, though it could improve in coherence and completeness by including more specific details and ensuring smoother transitions between sections.\n"]}]},{"cell_type":"markdown","source":["In the above example tdoc R1-2405963 summary generation, slightly higher BERT score is achieved which reflects on the rating given by gpt-4o. As such, BERT score is reflective indication of semantic similarity.  "],"metadata":{"id":"_K_X966xCwtk"}},{"cell_type":"markdown","source":["**Summary generation using LLM (round 8)**: Use the same prompt as in round 4,5,6,7 with gpt-4o model.  Summary generation for TDoc R1-2405975 to verify the consistency of the output. Temperature 0.1 is used instead of 0.01 (overly strict) or 0.7 (bit less strict)."],"metadata":{"id":"3_heJw_3zbud"}},{"cell_type":"code","source":["# Generate summary using lower temperature, specific prompt and gpt-4o for TDoc R1-2405975 (verify the consistency of the current prompt for producing output)\n","client = OpenAI(\n","    api_key=openAI_key\n",")\n","\n","response_R1_2405975_temp01 = client.chat.completions.create(\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are acting as a 3GPP Standard Delegate specializing in the RAN (Radio Access Network) Working Group 1 (WG1) for 5G/6G standardization. Generate a summary report from the text using terms common in 3GPP.\"},\n","    {\"role\": \"assistant\", \"content\": \"Title of the summary is 'Document summary: Document title, document number. Include the document title, meeting number, agenda item, document number, title, source, document for, location information at the top of the summary. Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary. If explanations or reasons for such observation is described in the document, provide a brief summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list proposals as items for example, 'proposal 1', 'proposal 2' etc. If such proposals exists in the document, include such proposals in the summary.\"},\n","    {\"role\": \"assistant\", \"content\": \"An explaination for the proposal is usally provided. Include such explaination in the summary.\"},\n","    {\"role\": \"system\", \"content\": \"Some documents list observations as items, for example, 'observation 1', 'observation 2' etc. If such observations exists in the document, include such observations in the summary.\"},\n","    {\"role\": \"user\", \"content\": input_text_R1_2405975}\n","],\n","    model=\"gpt-4o\",\n","    temperature=0.1,\n",")"],"metadata":{"id":"HEvljgxgzNR9","executionInfo":{"status":"ok","timestamp":1730331697283,"user_tz":240,"elapsed":13407,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","summary_R1_2405975_temp01 = response_R1_2405975_temp01.choices[0].message.content\n","# Print the message\n","print(summary_R1_2405975_temp01)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxZlozOIzmb-","executionInfo":{"status":"ok","timestamp":1730331722487,"user_tz":240,"elapsed":229,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"b55311f9-f0a3-4d66-b659-1cb1858fd886"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["**Document Summary:**\n","\n","**Document Title:** Discussion on specification support for beam management  \n","**Meeting Number:** 3GPP TSG RAN WG1 #118  \n","**Agenda Item:** 9.1.1  \n","**Document Number:** R1-2405975  \n","**Source:** CMCC  \n","**Document For:** Discussion & Decision  \n","**Location:** Maastricht, Netherlands  \n","**Date:** August 19th–August 23rd, 2024  \n","\n","**Introduction:**\n","This document discusses the specification impacts of AI-based beam management, focusing on agreements and proposals for both network (NW) and user equipment (UE) side models. It builds on agreements from the RAN1#117 meeting regarding AI/ML model-based beam management.\n","\n","**Agreements:**\n","1. **Performance Monitoring for BM-Case1 and BM-Case2:**\n","   - Support Type 1 performance monitoring with options for NW-side and UE-assisted performance monitoring.\n","   - Differential L1-RSRP reporting with legacy quantization is supported.\n","\n","2. **Inference Results for UE-sided Model:**\n","   - Predicted RSRP is based on AI/ML output for BM-Case 2.\n","\n","3. **Beam Report Content for NW-sided Model:**\n","   - Support for L1-RSRPs and beam information of Top M beams, configurable by gNB.\n","\n","**Proposals:**\n","1. **Training Data Collection:**\n","   - L1 signaling is supported for NW-sided training data collection.\n","   - Options for report contents include L1-RSRPs from one or two sets of beams.\n","\n","2. **Configuration of Set A:**\n","   - Enhance UE capability for RS measurement or support multiple resource sets in one CSI-ResourceConfig.\n","\n","3. **Rx Beam Assumption:**\n","   - Can be up to gNB implementation; indication may be needed for quasi-optimal Rx beam assumption.\n","\n","4. **Data Collection for UE-side Model:**\n","   - UE can request preferred set B; set B as AI model input is determined by gNB.\n","\n","5. **Inference and Monitoring:**\n","   - Top K beam sweeping procedure is configurable by gNB.\n","   - Temporal compression for overhead reduction is supported for NW-sided model inference reports.\n","\n","6. **Reporting and Monitoring:**\n","   - NW-side monitoring of NW-side AI/ML model is supported; KPI is up to gNB.\n","   - For UE-side model, Type 1 and Type 2 performance monitoring mechanisms are discussed.\n","\n","7. **Benchmark and KPI:**\n","   - Best beam(s) obtained by measuring beams of a set indicated by gNB is considered as the benchmark for monitoring performance comparison.\n","\n","**Conclusion:**\n","The document outlines several proposals to enhance AI-based beam management, focusing on training data collection, inference, and monitoring mechanisms. These proposals aim to improve beam prediction accuracy and system performance while considering specification impacts and reporting overhead.\n"]}]},{"cell_type":"code","source":["# Rate (semantic) the summary with gpt model\n","import openai\n","\n","openai.api_key = openAI_key\n","\n","# Rating prompt for OpenAI API\n","prompt_temp01 = f\"\"\"\n","Given the following original text and its generated summary, please evaluate the quality of the summary based on four criteria: relevance, coherence, completeness, and conciseness. For each criterion, provide a rating from 1 to 10, with 10 being the best. Then, give an overall rating.\n","\n","Original Text:\n","{input_text_R1_2405975}\n","\n","Generated Summary:\n","{summary_R1_2405975_temp01}\n","\n","Provide your response in the following format:\n","Relevance: [score]/10\n","Coherence: [score]/10\n","Completeness: [score]/10\n","Conciseness: [score]/10\n","Overall: [score]/10\n","\"\"\"\n","\n","# Send the prompt to OpenAI API\n","response_summary_rating_R1_2405975_temp01 = openai.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[{\"role\": \"user\", \"content\": prompt_temp01}], # the messages format\n","    temperature=0.01  # Set to a low temperature for more consistent ratings\n",")"],"metadata":{"id":"G5WzQ_0_zwrs","executionInfo":{"status":"ok","timestamp":1730331797045,"user_tz":240,"elapsed":4537,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Extract the response content\n","rating_summary_R1_2405975_temp01 = response_summary_rating_R1_2405975_temp01.choices[0].message.content\n","# Print the message\n","print(rating_summary_R1_2405975_temp01)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac-SVXUw0AX1","executionInfo":{"status":"ok","timestamp":1730331833286,"user_tz":240,"elapsed":219,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"e2130043-e45f-4240-a8c7-d370913611f4"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Relevance: 9/10  \n","The summary captures the main themes and key points of the original document, focusing on AI-based beam management, agreements, and proposals. However, it could include more specific details about the proposals and agreements to enhance relevance.\n","\n","Coherence: 8/10  \n","The summary is generally coherent, with a logical flow from introduction to agreements, proposals, and conclusion. However, some sections could be better connected to improve the overall narrative and understanding.\n","\n","Completeness: 7/10  \n","While the summary covers the main points, it lacks some specific details and nuances present in the original text, such as the detailed proposals and technical aspects of the agreements. Including these would provide a more comprehensive overview.\n","\n","Conciseness: 8/10  \n","The summary is concise and avoids unnecessary details, but it could be slightly more concise by eliminating some repetitive phrases and focusing on the most critical aspects of the document.\n","\n","Overall: 8/10  \n","The summary effectively captures the essence of the original document, but there is room for improvement in terms of completeness and coherence to provide a more detailed and connected overview.\n"]}]},{"cell_type":"code","source":["# Compute the BERT score\n","from bert_score import score\n","\n","# Calculate BERTScore\n","P, R, F1 = score([input_text_R1_2405975], [summary_R1_2405975_temp01], lang=\"en\", model_type=\"bert-base-uncased\")\n","\n","# Display BERTScore results\n","print(\"Precision:\", P.mean().item())\n","print(\"Recall:\", R.mean().item())\n","print(\"F1 Score:\", F1.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5wokR2D0Ml8","executionInfo":{"status":"ok","timestamp":1730331882726,"user_tz":240,"elapsed":8049,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"0e10b29d-1505-44ed-dfe8-4fe1cfe7755f"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6803195476531982\n","Recall: 0.6417273283004761\n","F1 Score: 0.6604601740837097\n"]}]},{"cell_type":"markdown","source":["**LLM (gpt) overall rating and BERT F1 score over temperature parameter**:\n","- The following plot shows the performance score such as gpt overall score and BERT F1 score against the temaperature value.  \n","- As observed, small values of temperature achieves higher scores (semantic)"],"metadata":{"id":"DOJgSbs-3UL1"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","\n","temperature_value = [0.1, 1.5, 0.01, 0.01, 0.7, 0.1, 0.1]\n","gpt_overall_score = [8, 3, 8, 8, 8, 8.5, 8]\n","BERT_F1_score = [0.60, 0.53, 0.65, 0.65, 0.66, 0.71, 0.66]\n","data = np.array([temperature_value, gpt_overall_score, BERT_F1_score])\n","data_df = pd.DataFrame(data=data.T, columns = ['Temperature value', 'gpt overall score', 'BERT F1 score'])\n","\n","fig, axes = plt.subplots(2, 1)\n","sns.scatterplot(data=data_df, x='Temperature value', y='gpt overall score', ax=axes[0])\n","sns.scatterplot(data=data_df, x='Temperature value', y='BERT F1 score', ax=axes[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"N92murntwJQV","executionInfo":{"status":"ok","timestamp":1730381780470,"user_tz":240,"elapsed":708,"user":{"displayName":"Sanjeewa Herath","userId":"07477979213875607396"}},"outputId":"5ad8a5e4-6cd2-424e-cf4e-8dd96687bef7"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='Temperature value', ylabel='BERT F1 score'>"]},"metadata":{},"execution_count":15},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["As observed from the gpt based semantic rating and BERT score, lower value of temperature is a preferred choice for summary generation.  "],"metadata":{"id":"j3u0u6UV00Pt"}},{"cell_type":"code","source":[],"metadata":{"id":"vv6xJV3ZCJKh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Discussion\n","**Summary generation**: LLM (gpt) openAI prompt can be used effectively for text summary generation. Different model such as gpt-4o, gpt-4o-mini, gpt-3.5-turbo have been tested. The generated summary performance is evaluated through gpt-4o semantic rating, BERT score (another semantic score) and ROUGE score (n-gram based).\n","\n","**Docx file processing for preparing LLM input text**: The original text in word (docx) format is transformed to text first. This text is passed to openAI API through as the input.\n","\n","**Impact of the model**: gpt-4o found to generate the best overall summary. The generated gpt-4o-mini does not interprete the prompt properly. Tests show that gpt-3.5-turbo does not have sufficient input tokens (because 16,385 tokens limit). The prompt is very important to define carefully with appropriate instructions specifying roles such as system, assistant and user. Lower values of temperature parameters such as 0.01, 0.1, 0.7 are more suitable to produce consistent and accurate summary. The prompt requires careful attention to avoid LLM model overfitting and underfitting.\n","\n","**Performance of the proposed approach**: The proposed LLM based summary generation has high semantic similiarity scores such gpt-4o rating and BERT score. As abstract summary generation is preferred over extractive summary for the project, high semantic rating is preferred. On the other hand, as expected, non semantic based ROUGE score does not appear to reflect the performance accurately. Therefore, a semantic based performance metric is more suitable metric for evaluating the performance of the TDoc summary generation task.  \n","\n","**Final model**: Appropriate model (gpt-4o) with appropriate prompt can produce high quality summary (gpt-4o semantic rating of 8 and higher, and BERT score 0.6 and higher).\n","\n","**Fine tuning to improve the model by user rated summaries**: As ground truth/reference summaries do not exist at the moment. Therefore, semantic score can not be calculated using sample reference/human summaries. As a next step, it is proposed to gather generated summaries along with user input ratings and use such collected data (user rated summaries) to fine-tune the LLM further.  "],"metadata":{"id":"4A8qBFuR2aNj"}}]}